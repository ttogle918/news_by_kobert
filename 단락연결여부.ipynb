{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "16o4vzYMJUgW8WgOPkZ61n3HPZDUNHnb8",
      "authorship_tag": "ABX9TyP4/Qsxxl/1zvRlOLyV9fl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/news_by_kobert/blob/master/%EB%8B%A8%EB%9D%BD%EC%97%B0%EA%B2%B0%EC%97%AC%EB%B6%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3주차 : 단락 연결 여부 확인\n",
        "\n",
        "## 1. 단락 유사도 파악\n",
        "\n",
        "2개 단락의 유사도 또는 연결성을 확인하는 것이 목적이다.  \n",
        "이를 위해 KLUE(Korean Lnaguage Understanding Evaluation)를 통해 배포된 BERT 모델을 이용할 것이다. "
      ],
      "metadata": {
        "id": "ibQYHPE9ehSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "M_mc7cfGEFJa"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForMaskedLM, TFBertForNextSentencePrediction, AutoTokenizer, FillMaskPipeline, BertTokenizer, PreTrainedTokenizer, BertConfig\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "2R3QHAiFEJ5T"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  KLUE는 총 8가지 자연어이해(NLU) task로 구성되어 있다.  \n",
        "\n",
        "    -Topic Classification  \n",
        "    -Semantic Textual  \n",
        "    -Natural Language Inference  \n",
        "    -Named Entity Recognition  \n",
        "    -Relation Extraction  \n",
        "    -Dependency parsing  \n",
        "    -Machine Reading Comprehension  \n",
        "    -Dialogue State Tracking  \n",
        "\n",
        "이 중에서 여기서 진행할 것은 Natural Language Inference(자연어추론)이다.  \n"
      ],
      "metadata": {
        "id": "hcdZhVxUdPwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 방법1. MASK에 들어갈 단어 예측"
      ],
      "metadata": {
        "id": "82fQQsUKH01i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)  #pytorch로 학습된 모델을 가져와 tf에서 사용\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")   #해당 모델이 학습되었을 당시 사용된 토크나이저"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcJ0IxAAEOSu",
        "outputId": "aecc3579-1fad-40aa-c802-93d448991cc9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer('축구는 정말 재미있는 [MASK]다.', return_tensors='tf')  \n",
        "print(inputs['input_ids'])\n",
        "print(inputs['token_type_ids'])   #문장 길이만큼의 0 시퀀스\n",
        "print(inputs['attention_mask'])   #실제 단어와 패딩 토큰을 구분하기 위한 어텐션 마스크"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ajGEcMEe9v",
        "outputId": "df79e059-47a6-440c-89ab-9f16a761e698"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[   2 4713 2259 3944 6001 2259    4  809   18    3]], shape=(1, 10), dtype=int32)\n",
            "tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n",
            "tf.Tensor([[1 1 1 1 1 1 1 1 1 1]], shape=(1, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)   #[MASK] 위치에 들어갈 상위 5개 출력\n",
        "pip('축구는 정말 재미있는 [MASK]다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYz8q_R4EqEV",
        "outputId": "e2e9823d-b791-4550-e509-48bd4a5ad5b6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8963507413864136,\n",
              "  'sequence': '축구는 정말 재미있는 스포츠 다.',\n",
              "  'token': 4559,\n",
              "  'token_str': '스포츠'},\n",
              " {'score': 0.025957776233553886,\n",
              "  'sequence': '축구는 정말 재미있는 거 다.',\n",
              "  'token': 568,\n",
              "  'token_str': '거'},\n",
              " {'score': 0.010033952072262764,\n",
              "  'sequence': '축구는 정말 재미있는 경기 다.',\n",
              "  'token': 3682,\n",
              "  'token_str': '경기'},\n",
              " {'score': 0.007924409583210945,\n",
              "  'sequence': '축구는 정말 재미있는 축구 다.',\n",
              "  'token': 4713,\n",
              "  'token_str': '축구'},\n",
              " {'score': 0.00784420408308506,\n",
              "  'sequence': '축구는 정말 재미있는 놀이 다.',\n",
              "  'token': 5845,\n",
              "  'token_str': '놀이'}]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#원래 단어는 '지지자'\n",
        "pip('더불어민주당 [MASK] 중 39.5%, 국민의당 지지자 중 28.8%, 기타 21%, 무당층의 16.2%, 개혁보수당 지지자 중 12.3%였다.')   #원래 단어는 '지지자'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkr3tuLLGUk-",
        "outputId": "01365d3b-a390-45ca-b302-413c90fd93af"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9840474724769592,\n",
              "  'sequence': '더불어민주당 지지자 중 39. 5 %, 국민의당 지지자 중 28. 8 %, 기타 21 %, 무당층의 16. 2 %, 개혁보수당 지지자 중 12. 3 % 였다.',\n",
              "  'token': 11006,\n",
              "  'token_str': '지지자'},\n",
              " {'score': 0.014456203207373619,\n",
              "  'sequence': '더불어민주당 지지층 중 39. 5 %, 국민의당 지지자 중 28. 8 %, 기타 21 %, 무당층의 16. 2 %, 개혁보수당 지지자 중 12. 3 % 였다.',\n",
              "  'token': 13755,\n",
              "  'token_str': '지지층'},\n",
              " {'score': 0.0006135492003522813,\n",
              "  'sequence': '더불어민주당 응답자 중 39. 5 %, 국민의당 지지자 중 28. 8 %, 기타 21 %, 무당층의 16. 2 %, 개혁보수당 지지자 중 12. 3 % 였다.',\n",
              "  'token': 9440,\n",
              "  'token_str': '응답자'},\n",
              " {'score': 0.00022629150771535933,\n",
              "  'sequence': '더불어민주당 지지 중 39. 5 %, 국민의당 지지자 중 28. 8 %, 기타 21 %, 무당층의 16. 2 %, 개혁보수당 지지자 중 12. 3 % 였다.',\n",
              "  'token': 4315,\n",
              "  'token_str': '지지'},\n",
              " {'score': 0.0002214877458754927,\n",
              "  'sequence': '더불어민주당 유권자 중 39. 5 %, 국민의당 지지자 중 28. 8 %, 기타 21 %, 무당층의 16. 2 %, 개혁보수당 지지자 중 12. 3 % 였다.',\n",
              "  'token': 7243,\n",
              "  'token_str': '유권자'}]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#원래 단어는 '이런'\n",
        "pip('75.3%는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1.5%였다. [MASK] 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUY5wcfRHJPU",
        "outputId": "4407bdb4-1b38-4dd9-be98-ce04c8a9f12b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.527259886264801,\n",
              "  'sequence': '75. 3 % 는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1. 5 % 였다. 이 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.',\n",
              "  'token': 1504,\n",
              "  'token_str': '이'},\n",
              " {'score': 0.19859308004379272,\n",
              "  'sequence': '75. 3 % 는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1. 5 % 였다. 조사 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.',\n",
              "  'token': 3742,\n",
              "  'token_str': '조사'},\n",
              " {'score': 0.17498789727687836,\n",
              "  'sequence': '75. 3 % 는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1. 5 % 였다. 이런 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.',\n",
              "  'token': 3667,\n",
              "  'token_str': '이런'},\n",
              " {'score': 0.043650247156620026,\n",
              "  'sequence': '75. 3 % 는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1. 5 % 였다. 이번 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.',\n",
              "  'token': 3686,\n",
              "  'token_str': '이번'},\n",
              " {'score': 0.023734353482723236,\n",
              "  'sequence': '75. 3 % 는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1. 5 % 였다. 설문 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.',\n",
              "  'token': 7509,\n",
              "  'token_str': '설문'}]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다음 문장 예측"
      ],
      "metadata": {
        "id": "l99_ydg3H8XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForNextSentencePrediction.from_pretrained('klue/bert-base', from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opjwu4pnH8pT",
        "outputId": "38b7cb39-65db-497e-b1ec-910a275e90ee"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForNextSentencePrediction: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XML파일에서 추출한 이어지는 두 개의 문장\n",
        "prompt = '이런 결과를 지난해 11월 행정자치부가 발표한 우리나라 인구수 5168만여명에 대입하면 ' \n",
        "next_sentence = ' 촛불집회 참가 경험이 있는 국민은 1199만여명으로 나온다.'\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
        "\n",
        "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
        "\n",
        "softmax = tf.keras.layers.Softmax()\n",
        "probs = softmax(logits)\n",
        "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJZSawr3IHA0",
        "outputId": "07b85f05-66e8-46cb-94f9-cad92a762779"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 예측 레이블 : [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XML파일에서 추출한 이어지는 제목, 문장\n",
        "prompt = '서브프라임 모기지 사태로 촉발된 미국의 금융위기가 미국 금융기관을' \n",
        "next_sentence = ' 몰락시키고, 세계 굴지의 자동차 회사들을 생존위기로 내몬 데 이어 최근 언론사까지 벼랑 끝으로 내몰고 있다.'\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
        "\n",
        "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
        "\n",
        "softmax = tf.keras.layers.Softmax()\n",
        "probs = softmax(logits)\n",
        "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Zgew-2ZOi0",
        "outputId": "f91db904-7d83-4427-c9cc-3500de890a72"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 예측 레이블 : [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XML파일에서 추출한 상관없는 두 개의 문장\n",
        "prompt = '75.3%는 전혀 참여한 적이 없다고 응답했고, 모른다고 답하거나 응답하지 않은 비율은 1.5%였다.' \n",
        "next_sentence = '이 목록에 오른 493개 차량 모델 중 LG화학과 삼성SDI의 배터리를 탑재한 차량은 하나도 없었다.'\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
        "\n",
        "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
        "\n",
        "softmax = tf.keras.layers.Softmax()\n",
        "probs = softmax(logits)\n",
        "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu24uemCIU5X",
        "outputId": "f07eb9f0-919d-41fe-f8bd-1667aac766a9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 예측 레이블 : [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XML파일에서 추출한 상관없는 제목, 문장\n",
        "prompt = '남의 집 제집이라 속여 팔았는데 사기 아니라고?' \n",
        "next_sentence = '충남 금산군이 환경부가 수변구역으로 지정한 임야에 버섯재배사 개발허가를 내줘 빈축을 사고 있다.'\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
        "\n",
        "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
        "\n",
        "softmax = tf.keras.layers.Softmax()\n",
        "probs = softmax(logits)\n",
        "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErAdB-jXZaBK",
        "outputId": "9af9acb1-6a03-4301-c8a3-143c15b74fae"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 예측 레이블 : [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model = TFBertForNextSentencePrediction.from_pretrained('klue/bert-base', from_pt=True) 에\n",
        "## 모두의말뭉치 Corpus를 이어서 학습"
      ],
      "metadata": {
        "id": "u9FzSkNdJdPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모두의말뭉치 파일 내 json 파일 목록\n",
        "def parse_paths(folder):\n",
        "    for current, dirs, files in os.walk(folder):\n",
        "        return [os.path.join(current, file) for file in files if file.endswith(\".json\")]\n",
        "\n",
        "#json 파일 내 기사 내용 추출\n",
        "def parse_contents(files):\n",
        "    result = []\n",
        "    for file in tqdm(files, desc=\"[Contents Parsing]\"):    #진행상황 확인용\n",
        "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "            contents = json.load(f)\n",
        "            for doc in contents['document']:\n",
        "                result_paragraph = []     #같은 기사 한문단\n",
        "                paragraph_id = doc['id']  #같은 기사 id\n",
        "                for paragraph in doc['paragraph']:\n",
        "                    if paragraph['id'][-2:] == '.1':   #기사의 제목 부분은 제외\n",
        "                        continue\n",
        "                    elif paragraph['id'][:17]==paragraph_id[:17] and paragraph['id'][-2:]=='.2':  #같은 id(같은 단락의 기사)의 첫줄이라면\n",
        "                        continue\n",
        "                    elif paragraph['id'][:17]==paragraph_id[:17] and paragraph['id'][-2:]!='.2':  #같은 id(같은 단락의 기사)의 첫줄이 아닌 문장\n",
        "                        result_paragraph.append(paragraph['form'])\n",
        "                    else:   #다른 id(다른 단락의 기사)라면\n",
        "                        result.append(result_paragraph)   #지금까지 id의 문장들은 result로\n",
        "                        result_pragraph = []   #result_paragraph 비우기\n",
        "                        paragraph_id = paragraph['id'][:17]\n",
        "                        result_paragraph.append(paragraph['form'])\n",
        "    print(\"[Contents Length] {0:,}\".format(len(result)))\n",
        "    \n",
        "    for i in range(len(result)):\n",
        "        pa = ''\n",
        "        for sentence in result[i]:\n",
        "            pa += f' {sentence}'\n",
        "            result[i] = pa    \n",
        "    return result\n",
        "\n",
        "data = parse_paths('/content/drive/MyDrive/Korpus')\n",
        "contents = parse_contents(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKx_U1usJXp9",
        "outputId": "1d0e04b7-ff2e-4ee5-8bc8-e4c40ae78f69"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Contents Parsing]: 100%|██████████| 35/35 [01:32<00:00,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Contents Length] 314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#같은 기사는 한 문단으로 처리됨\n",
        "contents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "7DGnA--UdBwr",
        "outputId": "e136144e-7502-4c93-a1c8-46aa08d6426c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 전남 목포시는 최근 이목이 집중되고 있는 근대역사문화공간 재생활성화 사업을 근대문화재 보존과 활용이라는 당초 취지대로 차질없이 추진하겠다고 밝혔다. 이 사업은 목포 원도심인 유달‧만호동 일대에 산재해 있는 근대건축물 등 문화유산을 보존하고 보수‧정비하는 사업으로 금년부터 향후 5년간 총 사업비 500억원이 투입된다. 목포시는 원도심 일대의 근대경관을 회복하고 거주민 생활여건 개선과 관광인프라 확충 등을 통해 이 지역을 전국적인 근대 문화유산의 보고로 만들어 나간다는 계획이다. 아울러, 최근 언론의 집중 보도로 목포 근대문화재에 대해 관심이 많아진 이 기회를 문화유산 보존의 필요성과 당위성을 널리 알리고 이에 대한 사회적 합의를 이루는 계기로 만드는 노력도 기울이기로 했다. 올 해는 종합정비계획을 수립하고 역사문화공간 내 건축자산 매입 및 정비에 나선다. 개별문화재로 등록된 15개소를 중심으로 우선 매입하고, 역사적‧건축적 가치가 높은 건축물과 경관을 훼손하는 건축물도 매입해서 공공재로의 활용을 확대한다는 계획이다. 특히, 목포시는 건축자산 매입 시 공정하고 투명한 행정절차를 통해 투기자본 유입을 원천 차단한다. 또, 근대역사문화공간 내 보존 활용, 관리 및 지원 기준에 관한 조례를 제정해 젠트리피케이션 발생을 예방하고, 특정 투기세력들이 수혜를 받을 수 없도록 제도적 장치를 마련하기로 했다. 목포시는 근대역사문화공간 재생 활성화 시범사업이 목포의 역사적 가치를 보존하면서 지역발전도 함께 이룰 수 있는 중요한 기회이자, 소중한 문화유산을 지키기 위해 꼭 필요한 사업이라는 점을 강조했다. 아울러, 문화재청, 관련 기관 등과 잘 협력해 사업을 본래의 취지대로 흔들림없이 추진해서 반드시 근대문화재 보존활용의 성공 모델로 만들어 간다는 방침을 확고히 했다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_paragraph = []\n",
        "for i in contents:\n",
        "    len_paragraph.append(len(i))\n",
        "    \n",
        "print(f'기사의 길이 : 최소 {min(len_paragraph)}자, 최대 길이 {max(len_paragraph)}자')\n",
        "#256자로 나누어 pre-trained 모델에 fine-tuning하기 위한 입력값으로 사용\n",
        "#최대길이인 4135자를 입력값으로 쓴다면, 4135 // 256 = 16개의 문단으로 나누어\n",
        "#각 문단의 다음 문단을 label로 입력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNEvgS6kdBuk",
        "outputId": "9c1ca55b-3014-4cd3-e1f8-6da1e6d59d1e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기사의 길이 : 최소 406자, 최대 길이 4135자\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SNRbrgEidBsF"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_xO_ujD1dBpl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yqd7lU0TdBmz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 마무리\n",
        "맞춤법 검사 : py-hanspell"
      ],
      "metadata": {
        "id": "Qw2W3erdXKFq"
      }
    }
  ]
}