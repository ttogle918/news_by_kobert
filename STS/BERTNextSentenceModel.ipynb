{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "데이터_라벨링_증식.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RYnZN7OwSROj"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMbfhrjC3Ul7sjW2ITbYyCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58230afd4bf0409ca32a6a99a035c399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e25b4601dd34424a92b2a6c570419ccc",
              "IPY_MODEL_d1441270ddb244e4bfc4f665e4196c79",
              "IPY_MODEL_4736de75e01d4adbac83ef73d1802192"
            ],
            "layout": "IPY_MODEL_eee150f2f4b94e9582e866bdd3ee9885"
          }
        },
        "e25b4601dd34424a92b2a6c570419ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8313315b92ea470c862053e36cf4a8fc",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb00af6399a41f49a721e5451d3d481",
            "value": "Validation sanity check:   0%"
          }
        },
        "d1441270ddb244e4bfc4f665e4196c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0255cc3c45ea4bb6a1b2462a0269180e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36d06f5cc64b4006a383007bfe0f539e",
            "value": 0
          }
        },
        "4736de75e01d4adbac83ef73d1802192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3337041c4c3f4df1be495347209e7f39",
            "placeholder": "​",
            "style": "IPY_MODEL_aff9fb37d3044fe682c77172600e9641",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "eee150f2f4b94e9582e866bdd3ee9885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8313315b92ea470c862053e36cf4a8fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb00af6399a41f49a721e5451d3d481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0255cc3c45ea4bb6a1b2462a0269180e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d06f5cc64b4006a383007bfe0f539e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3337041c4c3f4df1be495347209e7f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff9fb37d3044fe682c77172600e9641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/news_by_kobert/blob/master/STS/BERTNextSentenceModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 가져오기 시도\n",
        "\n",
        "데이터 증식은 성공!"
      ],
      "metadata": {
        "id": "K6j19bR8TG2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece transformers torch"
      ],
      "metadata": {
        "id": "gUFb-2H82WUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install torchtext pytorch-lightning\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "T0KrXnVl2X-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers numpy scikit-learn scipy nltk tqdm"
      ],
      "metadata": {
        "id": "gye9YOvE7RSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "pl.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IXmkDrPB2agz",
        "outputId": "13a6d77b-849d-451d-ecc8-6feb4f912faa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FR1XoGvL2co1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertModel, AdamW"
      ],
      "metadata": {
        "id": "WqchZTVT2ggT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "from typing import Callable, List, Tuple\n",
        "from seqeval.metrics import f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "Fg5S56W22hzQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# gpu 연산이 가능하면 'cuda:0', 아니면 'cpu' 출력\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device, torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWmKplsf2kT3",
        "outputId": "148740f8-e0a4-4927-cdd9-1e50c11805a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w59GBsmp6OA",
        "outputId": "88e39f49-6278-4fdf-a14a-300fe61a63ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/NextLab/news_class9x1400'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_splicing(text, max_len) :\n",
        "  before_idx = 0\n",
        "  li = []\n",
        "  i = 0\n",
        "  while True:\n",
        "    if before_idx+max_len < len(text) :\n",
        "      li.append( [text[before_idx:before_idx+max_len], i] )\n",
        "      i += 1\n",
        "    else :\n",
        "      li.append(  [text[before_idx:], i] )\n",
        "      if len(li) < 2 :\n",
        "        return None   # 연결할 단락이 없으므로 dataset에 넣지 않는다.\n",
        "      return li\n",
        "\n",
        "    before_idx += max_len\n",
        "  return li"
      ],
      "metadata": {
        "id": "mE5gxyglqC-_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 128"
      ],
      "metadata": {
        "id": "xxAUazIhq7AJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"특정한 풍경을 통하여 개인적인 감정을 시각화한 사진전\n",
        "박진호는 1990년대에 자신의 벗은 몸을 복사기로 복제하여 실험적인 결과물을 생산한 작가로서 유명하다.\n",
        "그런데 이번에는 새벽녘의 달과 하늘을 카메라 앵글에 담아서 감상적인 이미지를 전시하였다.\n",
        "작가가 이번에 인사동에 있는 나우 갤러리에서 전시한 작품들은 달빛과 구름 낀 새벽하늘을 감성적인 느낌이 드는 결과물로 재구성하여 보여주고 있다.\n",
        "전시 작품마다 외형적으로 컬러가 자극적이고 전체적으로 톤도 어두워서 보는 이들을 감성적으로 동화시키는 표현전략을 구사하고 있다는 것을 알 수 있다.\n",
        "작가가 관심을 갖고 카메라 앵글에 담은 대상을 구체적으로 살펴보면 구름과 산봉우리 그리고 강변 풍경이다.\n",
        "그런데 왠지 표현대상과 소재가 낯설게 느껴지지 않고 너무나도 익숙하다.\n",
        "왜 그런 것 일까?\n",
        "그것은 작가가 표현대상으로 선택한 소재와 표현방식이 ‘일요 사진가’라고 일컬어지는 아마추어 작가들이 흔히 찍는 탐미적인 사진과 별다른 차이점이 없기 때문이다.\n",
        "사진은 시각예술이다.\n",
        "그러므로 작가가 표현하고자하는 주제와 관계없이 외형적으로 보여 지고 느껴지는 것이 무엇보다도 중요하다.\n",
        "그런데도 아쉽게도 이번에 박진호가 발표한 풍경사진들은 외형적으로 아마추어 작가들의 유미주의적이고 감상적인 작품과의 차별화에 실패하였다.\n",
        "풍경사진이나 정물사진은 절제된 프레이밍과 세련된 컬러와 톤이 작품의 완성도를 보장하는데 있어서 중요한 요소로 작용한다.\n",
        "그러므로 주제선택과 더불어서 외형적으로는 그것을 좀 더 염두에 두고 작업을 진행을 했다면 최종 결과물의 완성도가 달라졌을 것이다.\n",
        "이번에 작가가 발표한 작품들은 누구나 폭넓게 이해할 수 있는 소재와 표현방식을 보여주고 있다. 하지만 자신만의 조형언어를 보여주는 데는 소홀히 했다는 것이 느껴진다.\n",
        "그래서 여러 가지로 아쉬운 점이 많은 전시가 되었다. 하지만 자신의 감정을 솔직하게 표현하여 결과물을 생산 한 것은 분명하다.\n",
        "특정한 풍경을 통하여 개인적인 감정을 시각화 전시이다.\"\"\".replace('\\n', '')\n",
        "\n",
        "text_splicing(text, max_len) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaLWkKfjrzPC",
        "outputId": "ac3828b2-1a3b-4f32-9ab4-5863900f2cca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['특정한 풍경을 통하여 개인적인 감정을 시각화한 사진전박진호는 1990년대에 자신의 벗은 몸을 복사기로 복제하여 실험적인 결과물을 생산한 작가로서 유명하다.그런데 이번에는 새벽녘의 달과 하늘을 카메라 앵글에 담아서 감상적인 이미지를',\n",
              "  0],\n",
              " [' 전시하였다.작가가 이번에 인사동에 있는 나우 갤러리에서 전시한 작품들은 달빛과 구름 낀 새벽하늘을 감성적인 느낌이 드는 결과물로 재구성하여 보여주고 있다.전시 작품마다 외형적으로 컬러가 자극적이고 전체적으로 톤도 어두워서 보는 ',\n",
              "  1],\n",
              " ['이들을 감성적으로 동화시키는 표현전략을 구사하고 있다는 것을 알 수 있다.작가가 관심을 갖고 카메라 앵글에 담은 대상을 구체적으로 살펴보면 구름과 산봉우리 그리고 강변 풍경이다.그런데 왠지 표현대상과 소재가 낯설게 느껴지지 않고 ',\n",
              "  2],\n",
              " ['너무나도 익숙하다.왜 그런 것 일까?그것은 작가가 표현대상으로 선택한 소재와 표현방식이 ‘일요 사진가’라고 일컬어지는 아마추어 작가들이 흔히 찍는 탐미적인 사진과 별다른 차이점이 없기 때문이다.사진은 시각예술이다.그러므로 작가가 ',\n",
              "  3],\n",
              " ['표현하고자하는 주제와 관계없이 외형적으로 보여 지고 느껴지는 것이 무엇보다도 중요하다.그런데도 아쉽게도 이번에 박진호가 발표한 풍경사진들은 외형적으로 아마추어 작가들의 유미주의적이고 감상적인 작품과의 차별화에 실패하였다.풍경사진이',\n",
              "  4],\n",
              " ['나 정물사진은 절제된 프레이밍과 세련된 컬러와 톤이 작품의 완성도를 보장하는데 있어서 중요한 요소로 작용한다.그러므로 주제선택과 더불어서 외형적으로는 그것을 좀 더 염두에 두고 작업을 진행을 했다면 최종 결과물의 완성도가 달라졌을',\n",
              "  5],\n",
              " [' 것이다.이번에 작가가 발표한 작품들은 누구나 폭넓게 이해할 수 있는 소재와 표현방식을 보여주고 있다. 하지만 자신만의 조형언어를 보여주는 데는 소홀히 했다는 것이 느껴진다.그래서 여러 가지로 아쉬운 점이 많은 전시가 되었다. 하',\n",
              "  6],\n",
              " ['지만 자신의 감정을 솔직하게 표현하여 결과물을 생산 한 것은 분명하다.특정한 풍경을 통하여 개인적인 감정을 시각화 전시이다.', 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "content = []\n",
        "for (path, dir, files) in os.walk(data_path):\n",
        "    for filename in files:\n",
        "        ext = os.path.splitext(filename)[-1]\n",
        "        if ext == '.txt':\n",
        "            with open(\"%s/%s\" % (path, filename), encoding=\"utf-8\") as f:\n",
        "              label = path[path.rindex('/')+1:]\n",
        "              text = f.read()\n",
        "              temp_list = text_splicing(text.replace('\\n', ' '), max_len)\n",
        "              if temp_list is not None :\n",
        "                content.extend(temp_list)\n",
        "\n",
        "len(content), len(content[0]) # content : [(text, 단락 번호)]"
      ],
      "metadata": {
        "id": "MABJQRdUrJth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1NkS6qwBQsn",
        "outputId": "8c44eedc-c331-461d-e54b-18837876488c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78845"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label : 0 is True, 1 is False\n",
        "import random\n",
        "i, len_content = 0, len(content)\n",
        "dataset = []\n",
        "right_li, wrong_li = [], []   # 추가할 list\n",
        "before_text = content[0][0]\n",
        "while i < len_content :\n",
        "  text = content[i][0]\n",
        "  idx = content[i][1]\n",
        "  if idx > 0 :    # label : right\n",
        "    right_li.append( (before_text, text, 0) )   # right\n",
        "\n",
        "  # idx == 0 and len(li) == 1 인 경우는 없다. file read할 때 넣지 않았다. \n",
        "  elif idx == 0 and len(right_li) > 1 :   # label : wrong \n",
        "    len_li = len(right_li)\n",
        "    for t in right_li :\n",
        "      rd = random.randint(0, len_content-len_li-1)\n",
        "      wrong_text = content[rd][0] if rd < i-len_li else content[rd+len_li][0]   # random으로 고르기 ( 같은 기사 제외 )\n",
        "      wrong_li.append((t[0], wrong_text, 1) )\n",
        "    dataset.extend(right_li)\n",
        "    dataset.extend(wrong_li)\n",
        "    right_li, wrong_li = [], []\n",
        "  before_text = text\n",
        "  i += 1\n",
        "len_content, len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9zgCD5pri-p",
        "outputId": "ed0cb184-8877-40d4-aa3f-3208894f4565"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78845, 149252)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtP9xT_5EVzA",
        "outputId": "2c952e75-77ed-4eba-9c68-bf6f58ca211e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('임원들 보수 총액이 아닌 임원 개인별 보수가 공시되도록 했다. 이 의원은 18개 국내은행이 정부로부터 대외채무 지급보증을 받으면서 은행장의 연봉 삭감 결의를 했는데 과연 삭감내역이 적정한지 알기 어렵기 때문에 각 임원별 공시를 도',\n",
              "  ' 되면 P씨의 부모님 부양 부담이 많이 덜어질 수 있기 때문이다. 여유가 있다면 자녀에게 국민연금을 물려주는 것도 좋은 선물이 된다. 18세 이상의 자녀를 국민연금에 임의가입시키고 그 돈을 부모님이 내주는 것이다. 이 경우 부모님',\n",
              "  1),\n",
              " ('입할 필요가 있다고 말했다. 또한 이 의원은 이전부터 제기되어온 문제인 지배주주가 보수결정을 좌우하고 임원의 독립성을 침해하는 문제도 임원별로 보수가 공시되어야 방지될 수 있다며 개정안이 통과되면 책임경영은 물론이고 임원 보수와 ',\n",
              "  '들 간에 마찰이 빚어졌다. 주민들과의 마찰로 인해 측량이 불가능하다고 판단한 공사 직원들이 측량을 포기하고 돌아가기로 결정하면서 이날 일은 거기서 일단락되는 듯했다. 하지만 사무실로 돌아가겠다던 공사 직원들은 길을 우회하여 강정천',\n",
              "  1),\n",
              " ('업무 간의 상관성도 향상시켜줄 것이라고 말했다. 이 의원은 임원의 독립성을 강화하고 회사의 지배주주가 임원 보수의 명목으로 우회배당을 하거나 회사 재산을 처분하는 등 회사 재산의 사용에서 사익만을 추구하는 행동을 억제하고, 적정성',\n",
              "  '세 규모는 63조8000억 원이며 대기업과 고소득층의 감세 혜택분은 31조 원(48.6%), 중소기업·중산서민층은 32.5조 원(50.9%)이라고 발표했다. 하지만 국회예산정책처(NABO)의 자료를 토대로 하면 문 후보의 말이 옳',\n",
              "  1)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split Train and Validation data\n",
        "train, test = train_test_split(dataset[:1000], test_size=0.2, random_state=0, shuffle=True)\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=0, shuffle=True)\n",
        "print(\"train :\", len(train), \"  val :\", len(val), \"  test :\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMkcFFbrsXhh",
        "outputId": "93a269bc-20fc-4831-915a-30aa5bc50c02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train : 640   val : 160   test : 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del content\n",
        "del dataset\n",
        "del right_li\n",
        "del wrong_li"
      ],
      "metadata": {
        "id": "nNYBWi0xduEq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "id": "K0ynXgR8TVY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944d24ca-08e6-48ca-d3af-9bdb6a379813"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('일 먼저 항공방제를 거부했다. 항공방제의 특성상 어느 한 곳만 빼고 농약을 할 수 없기 때문이었다. 이로 인해 주변 사람들한테 눈총도 많이 받았다. 주민들의 심정은 충분히 이해를 하죠. 과수 농사는 한 번 망치면 끝이거든요. 성공',\n",
              " '당 대전시당 관계자는 이윤호 장관의 의중을 잘 안다, 정책보좌관에게 확인했더니 (대전시장 출마설은) 전혀 사실이 아니라고 얘기하고 있다고 전했다. 이 관계자는 현 시장이 당연히 공천 받는 것은 아니고 다른 분이 출마한다고 하면 경',\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 여기까지 ok"
      ],
      "metadata": {
        "id": "OVwFhiQRTSh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/jhgan00/ko-sentence-transformers\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# import numpy as np\n",
        "\n",
        "# embedder = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
        "\n",
        "# model_path = '/content/drive/My Drive/Colab Notebooks/NextLab/nli/result.pt'\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# import numpy as np\n",
        "# from transformers import BertModel, DistilBertModel\n",
        "# distilbert_model = DistilBertModel.from_pretrained('monologg/distilkobert')"
      ],
      "metadata": {
        "id": "k5UqSuURTVVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6pQcOZCR2SoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch, transformers\n",
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"snunlp/KR-Medium\", do_lower_case=False)\n",
        "\n",
        "model = BertForNextSentencePrediction.from_pretrained(\"snunlp/KR-Medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flxSYBROmWkY",
        "outputId": "b7edd093-51c9-4fab-b083-32900d7b07c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at snunlp/KR-Medium were not used when initializing BertForNextSentencePrediction: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# 이어지는 두 개의 문장\n",
        "prompt = \" 메카로 불리는 걸까. 암베르크 공장은 커다란 병원 수술\"\n",
        "next_sentence = \"실 같았다. 안내자가 “건초 더미에서 바늘을 찾는 게 더 쉬울 것”이라고 말할 정도로 먼지 한점 없이 깨끗했다.\"\n",
        "encoding = tokenizer(prompt, next_sentence, return_tensors='pt', padding=True )    # 두 문장을 이어붙여서 encode\n",
        "print(type(encoding))\n",
        "print(encoding)\n",
        "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
        "print(logits)\n",
        "softmax = torch.nn.Softmax()\n",
        "probs = softmax(logits)\n",
        "print(probs)\n",
        "print('최종 예측 레이블 :', torch.argmax(probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WEuRwWjm2Fk",
        "outputId": "46f03493-546e-4d68-d894-c0bcb63a8605"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
            "{'input_ids': tensor([[    2,  2850,  5363,  5016, 17396,  1965,  5045,    18,  3525,  5467,\n",
            "         14118, 11525,  5019,  4198,  5042,  5109, 10016, 12728,     3,  3389,\n",
            "          1936,  8660,    18, 13544,  8573,   211,  1963,  5817,  2436,  5031,\n",
            "          8454,  2955,  5946,  5008, 16657,  1977,  2436,  3349,  5340,  1969,\n",
            "           212,  9118, 13555, 10845, 14089,  4494,  5450,  9043, 10269,  8468,\n",
            "            18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])}\n",
            "tensor([[ 1.5886, -0.8314]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.9183, 0.0817]], grad_fn=<SoftmaxBackward0>)\n",
            "최종 예측 레이블 : tensor(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([2, 3])"
      ],
      "metadata": {
        "id": "v8xJmjOZFtgO",
        "outputId": "e31e7e3f-b63b-4504-e535-2ee0b79244f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(0), tokenizer.decode(1)  # unk : 없는 글자, unknown, pad 문장의 길이를 맞추기위함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu_cY3HD3KOK",
        "outputId": "48baa080-7738-40d8-8f5e-3ecb048c3489"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[ P A D ]', '[ U N K ]')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tokenization_kobert import KoBertTokenizer\n",
        "# tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "metadata": {
        "id": "U2-bwKUKlT0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
        "# model = TFBertForNextSentencePrediction.from_pretrained('klue/bert-base', from_pt=True)"
      ],
      "metadata": {
        "id": "91kZRcBO7K7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Korean RoBERTa\n",
        "+ KorSTS \n",
        "+ Kr-bert-base\n",
        "\n",
        "SentenceTransformer : 문장, 텍스트, 이미지 임베딩, cosine 유사성과 비교하여 유사한 의미를 가진 문장 찾기"
      ],
      "metadata": {
        "id": "vbrcrZSkOrpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForNextSentencePrediction, BertConfig\n",
        "import torch\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")\n",
        "# prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
        "# next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
        "# encoding = tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n",
        "# outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
        "# logits = outputs.logits\n",
        "# assert logits[0, 0] < logits[0, 1]  # next sentence was random"
      ],
      "metadata": {
        "id": "CAIq97HpyStW"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "model = BertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config"
      ],
      "metadata": {
        "id": "h9QnB1gt1uEE"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CorpusDataset"
      ],
      "metadata": {
        "id": "UPkYoWMAKaTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CorpusDataset(Dataset):\n",
        "    def __init__(self, sentences, transform: Callable):\n",
        "        self.sentences = sentences\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt = self.sentences[idx][0]\n",
        "        next_sentence = self.sentences[idx][1]\n",
        "        label = self.sentences[idx][2]\n",
        "        (\n",
        "            input_ids,\n",
        "            attention_mask,\n",
        "            token_type_ids,\n",
        "            label, \n",
        "        ) = self.transform(prompt, next_sentence, label)\n",
        "\n",
        "        return input_ids, attention_mask, token_type_ids, label"
      ],
      "metadata": {
        "id": "IUOliQisGaBx"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_prompt = tokenizer.tokenize(prompt)    # 두 문장을 이어붙여서 encode\n",
        "tok_next_sen = tokenizer.tokenize(next_sentence)    # 두 문장을 이어붙여서 encode\n",
        "\n",
        "input_ids = [2] + tokenizer.convert_tokens_to_ids(tok_prompt) + [3]    # 처음과 끝 표시\n",
        "input_ids_next_sen = [2]+ tokenizer.convert_tokens_to_ids(tok_next_sen)+ [3]\n",
        "\n",
        "slicing_idx = 0\n",
        "if len(input_ids) + len(input_ids_next_sen) > max_len :\n",
        "  slicing_idx = len(input_ids) + len(input_ids_next_sen) - max_len // 2 + 2\n",
        "  input_ids = [2] + input_ids[slicing_idx:]\n",
        "  input_ids_next_sen = input_ids_next_sen[:-slicing_idx] + [3]\n",
        "\n",
        "token_type_ids = [0]*len(input_ids)\n",
        "token_type_ids.extend([1]*len(input_ids_next_sen))\n",
        "input_ids.extend(input_ids_next_sen)\n",
        "attention_mask = [1] * len(token_type_ids)\n",
        "pad_length = max_len-len(input_ids)\n",
        "\n",
        "input_ids.extend([0] * pad_length)\n",
        "token_type_ids.extend([0] * pad_length) # pad : 0\n",
        "attention_mask.extend([0] * pad_length) # pad : 0"
      ],
      "metadata": {
        "id": "VrZUyp77NC1r",
        "outputId": "2a098545-3d7b-4833-b054-788e58cbc00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 53 53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessor"
      ],
      "metadata": {
        "id": "WI0AtpHWKdM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "# encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
        "\n",
        "class Preprocessor :\n",
        "    def __init__(self, max_len: int):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"snunlp/KR-Medium\", do_lower_case=False)\n",
        "        self.max_len = max_len\n",
        "        self.pad_token_id = 0\n",
        "\n",
        "    def get_input_features(self, prompt, next_sentence, label\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"문장과 띄어쓰기 tagging에 대해 feature로 변환한다.\n",
        "\n",
        "        Args:\n",
        "            sentence: 문장\n",
        "            tags: 띄어쓰기 tagging\n",
        "\n",
        "        Returns:\n",
        "            feature를 리턴한다.\n",
        "            input_ids, attention_mask, token_type_ids, slot_labels\n",
        "        \"\"\"\n",
        "        tok_prompt = tokenizer.tokenize(prompt)    # 두 문장을 이어붙여서 encode\n",
        "        tok_next_sen = tokenizer.tokenize(next_sentence)    # 두 문장을 이어붙여서 encode\n",
        "\n",
        "        input_ids = [2] + tokenizer.convert_tokens_to_ids(tok_prompt) + [3]    # 처음과 끝 표시\n",
        "        input_ids_next_sen = [2]+ tokenizer.convert_tokens_to_ids(tok_next_sen)+ [3]\n",
        "\n",
        "        slicing_idx = 0\n",
        "        if len(input_ids) + len(input_ids_next_sen) > max_len :\n",
        "          slicing_idx = len(input_ids) + len(input_ids_next_sen) - max_len // 2 + 2\n",
        "          input_ids = [2] + input_ids[slicing_idx:]\n",
        "          input_ids_next_sen = input_ids_next_sen[:-slicing_idx] + [3]\n",
        "\n",
        "        token_type_ids = [0]*len(input_ids)\n",
        "        token_type_ids.extend([1]*len(input_ids_next_sen))\n",
        "        input_ids.extend(input_ids_next_sen)\n",
        "        attention_mask = [1] * len(token_type_ids)\n",
        "        pad_length = max_len-len(input_ids)\n",
        "\n",
        "        input_ids.extend([0] * pad_length)\n",
        "        token_type_ids.extend([0] * pad_length) # pad : 0\n",
        "        attention_mask.extend([0] * pad_length) # pad : 0\n",
        "\n",
        "        input_ids = torch.tensor(input_ids, dtype=torch.int)\n",
        "        attention_mask = torch.tensor(attention_mask, dtype=torch.int)\n",
        "        token_type_ids = torch.tensor(token_type_ids, dtype=torch.int)\n",
        "\n",
        "        label = [1.0, 0.] if label == 0 else [0., 1.0]\n",
        "        label = torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "        return input_ids, attention_mask, token_type_ids, label"
      ],
      "metadata": {
        "id": "R3Z2VLbaFEK8"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERTNextSentenceModel"
      ],
      "metadata": {
        "id": "RYnZN7OwSROj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from math import log\n",
        "class BertOnlyNSPHead(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return seq_relationship_score\n",
        "\n",
        "\n",
        "class BERTNextSentenceModel(pl.LightningModule):\n",
        "    def __init__(self, config, dataset):\n",
        "        super().__init__()\n",
        "        print(\"init\")\n",
        "        self.config = config\n",
        "        self.dataset = dataset\n",
        "        self.slot_labels_type = [0, 1]\n",
        "        self.pad_token_id = 0\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        self.bert_config = BertConfig.from_pretrained(\n",
        "            self.config.bert_model, num_labels=2\n",
        "        )\n",
        "        self.model = BertModel.from_pretrained(\n",
        "            self.config.bert_model, config=self.bert_config\n",
        "        )\n",
        "        self.cls = BertOnlyNSPHead(config)\n",
        "        self.dropout = nn.Dropout(self.config.dropout_rate)\n",
        "        self.linear = nn.Linear(\n",
        "            self.bert_config.hidden_size, len(self.slot_labels_type)\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "        input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None,\n",
        "        head_mask=None, inputs_embeds=None, labels=None, output_attentions=None, output_hidden_states=None,\n",
        "        return_dict=None, **kwargs, ):\n",
        "        \"\"\"\n",
        "        return NextSentencePredictorOutput(\n",
        "            loss=next_sentence_loss,\n",
        "            logits=seq_relationship_scores,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"forward\")\n",
        "        logits = self.model(input_ids, token_type_ids=token_type_ids)[0]\n",
        "        # print(logits)\n",
        "        probs = self.softmax(logits)\n",
        "        print(probs)\n",
        "        # return torch.relu(self.linear(probs.view(probs.size(0), -1)))\n",
        "        # output = self.model(input_ids, attention_mask, token_type_ids, position_ids, \n",
        "        #                        head_mask, inputs_embeds, labels,\n",
        "        #                        output_attentions, output_hidden_states, return_dict, **kwargs,)\n",
        "        return probs\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        print(\"training_step\")\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "        \n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            labels=slot_label_ids,\n",
        "        )\n",
        "\n",
        "        loss = self._calculate_loss(outputs, slot_label_ids) # slot_labels : labels\n",
        "        f1 = self._f1_score(outputs, slot_label_ids)\n",
        "        acc = self._calculate_accuracy(outputs, slot_label_ids)\n",
        "        tensorboard_logs = {'train_loss': loss, 'train_f1':f1, 'train_acc':acc}\n",
        "        return {\"loss\": loss, \"f1\": f1, \"acc\": acc, \"log\": tensorboard_logs}\n",
        "\n",
        "    def training_end(self, batch, batch_nb):\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        loss = self._calculate_loss(outputs, slot_label_ids) # slot_labels : labels\n",
        "        f1 = self._f1_score(outputs, slot_label_ids)\n",
        "        acc = self._calculate_accuracy(outputs, slot_label_ids)\n",
        "\n",
        "        tensorboard_logs = {'train_loss': loss, 'train_f1':f1, 'train_acc':acc}\n",
        "        print(\"training_end : \", tensorboard_logs)\n",
        "        return {\"loss\": loss, \"f1\": f1, \"acc\": acc, \"log\": tensorboard_logs}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        super().on_train_epoch_end()\n",
        "        print(\"training_epoch_end\")\n",
        "      \n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        loss = self._calculate_loss(outputs, slot_label_ids)\n",
        "        val_f1 = self._f1_score(slot_label_ids, outputs)\n",
        "        val_acc = self._calculate_accuracy(outputs, slot_label_ids)\n",
        "        return {\"val_loss\": loss, \"val_f1\": val_f1, 'val_acc':val_acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        # val_f1 = torch.stack([x['val_f1'] for x in outputs]).mean()\n",
        "        val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'val_loss': avg_loss, 'val_acc':val_acc}\n",
        "        print('validation_epoch_end : ', tensorboard_logs)\n",
        "        self.log(\"validation_epoch_end : tensorboard_logs \", tensorboard_logs)\n",
        "\n",
        "        return {'val_acc':val_acc, 'val_loss': avg_loss, 'log': tensorboard_logs}\n",
        "    \n",
        "    def validation_end(self, outputs):\n",
        "        val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        val_acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
        "        # val_f1 = torch.stack([x[\"val_f1\"] for x in outputs]).mean()\n",
        "        tensorboard_logs = {\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\" : val_acc\n",
        "        }\n",
        "        print(\"validation_end : \", tensorboard_logs)\n",
        "        return {'val_acc':val_acc, 'val_loss': val_loss, 'log': tensorboard_logs}\n",
        "    \n",
        "    def test_step(self, batch, batch_nb):\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        # f1 = self._f1_score(gt_slot_labels, pred_slot_labels)\n",
        "        acc = self._calculate_accuracy(outputs, slot_label_ids)\n",
        "        loss = self._calculate_loss(outputs, slot_label_ids)\n",
        "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
        "\n",
        "    def test_end(self, outputs):\n",
        "        test_f1 = torch.stack([x[\"test_f1\"] for x in outputs]).mean()\n",
        "        test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
        "        test_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
        "        self.log(\"test_loss\", test_loss)\n",
        "        self.log(\"test_acc\", test_acc)\n",
        "        self.log(\"test_f1\", test_f1)\n",
        "        print('test_end')\n",
        "        return {\"pred_slot_labels\" : [x[\"pred_slot_labels\"] for x in outputs], \"test_loss\": test_loss, \"test_f1\": test_f1, \"test_acc\": test_acc}\n",
        "    \n",
        "    def test_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "        f1 = torch.stack([x['test_f1'] for x in outputs]).mean()\n",
        "        acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'test_loss': avg_loss, 'test_f1':f1, 'test_acc':acc}\n",
        "        print('test_epoch_end : ', tensorboard_logs)\n",
        "        self.log(\"test_epoch_end : tensorboard_logs \", tensorboard_logs)\n",
        "        return {'test_acc':acc, 'test_loss': avg_loss, 'test_f1':f1, 'log': tensorboard_logs}\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):   # prediction : forward(), predict_step()\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch    # slot_label은 없음.\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        pred_slot_labels, gt_slot_labels = self._convert_ids_to_labels(\n",
        "            outputs, slot_label_ids\n",
        "        )\n",
        "        return {'pred_slot_labels':pred_slot_labels, 'gt_slot_labels': gt_slot_labels}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"train\"], batch_size=self.config.eval_batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"val\"], batch_size=self.config.eval_batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"test\"], batch_size=self.config.eval_batch_size)\n",
        "\n",
        "    def pred_dataloader(self, dataset):\n",
        "        return DataLoader(dataset, batch_size=1)\n",
        "\n",
        "    def _calculate_loss(self, outputs, labels):\n",
        "        # active_logits = outputs.view(-1, len(self.slot_labels_type))\n",
        "        # active_labels = labels.view(-1)\n",
        "        print(\"outputs\",outputs)\n",
        "        print(\"outputs[3]\",outputs[3])\n",
        "        print(\"labels\",labels)\n",
        "        loss = F.cross_entropy(outputs[3], labels)\n",
        "        return loss\n",
        "        \n",
        "    def _calculate_accuracy(self, outputs, labels):\n",
        "        active_logits = outputs.view(-1, len(self.slot_labels_type))\n",
        "        active_labels = labels.view(-1)\n",
        "        accuracy = accuracy_score(active_logits, active_labels)\n",
        "        return accuracy\n",
        "\n",
        "    def _f1_score(self, gt_slot_labels, pred_slot_labels):\n",
        "        return torch.tensor(\n",
        "            f1_score(gt_slot_labels, pred_slot_labels), dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    def _convert_ids_to_labels(self, outputs, slot_labels):\n",
        "        _, y_hat = torch.max(outputs, dim=2)\n",
        "        y_hat = y_hat.detach().cpu().numpy()\n",
        "        slot_label_ids = slot_labels.detach().cpu().numpy()\n",
        "\n",
        "        slot_label_map = {i: label for i, label in enumerate(self.slot_labels_type)}\n",
        "        slot_gt_labels = [[] for _ in range(slot_label_ids.shape[0])]\n",
        "        slot_pred_labels = [[] for _ in range(slot_label_ids.shape[0])]\n",
        "\n",
        "        for i in range(slot_label_ids.shape[0]):\n",
        "            for j in range(slot_label_ids.shape[1]):\n",
        "                if slot_label_ids[i, j] != self.pad_token_id:\n",
        "                    slot_gt_labels[i].append(slot_label_map[slot_label_ids[i][j]])\n",
        "                    slot_pred_labels[i].append(slot_label_map[y_hat[i][j]])\n",
        "\n",
        "        return slot_pred_labels, slot_gt_labels"
      ],
      "metadata": {
        "id": "hkPjDg8xRzJc"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "gKfOPREESKO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# yaml 파일 대신에 객체로 생성\n",
        "from transformers import BertModel, BertConfig\n",
        "class Config(BertConfig):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.task= 'kor_nextsentence_prediction_20220322'\n",
        "    self.log_path= data_path+'/logs'\n",
        "    self.bert_model = \"snunlp/KR-Medium\"    # 수정해야함!\n",
        "    self.max_len= 256\n",
        "    self.train_batch_size= 128\n",
        "    self.eval_batch_size= 128\n",
        "    self.dropout_rate= 0.1\n",
        "    self.gpus= torch.cuda.device_count()\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "SjNMG75CSJsR"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "RADAOb-DidY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = Preprocessor(config.max_len)"
      ],
      "metadata": {
        "id": "cMHINMMQf-wi"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "dataset['train'] = CorpusDataset(train, preprocessor.get_input_features)\n",
        "dataset['val'] = CorpusDataset(val, preprocessor.get_input_features)\n",
        "dataset['test'] = CorpusDataset(test, preprocessor.get_input_features)"
      ],
      "metadata": {
        "id": "oM0u4PTTScqM"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['train']),len(dataset['train'][0]), dataset['train'][0]"
      ],
      "metadata": {
        "id": "RIO_L_o9Upig",
        "outputId": "89e4dd0b-210b-4dc1-c59e-005214135382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640,\n",
              " 4,\n",
              " (tensor([    2,  3749,  8951, 11769,  5112, 10042, 10714,  8468,    18, 11769,\n",
              "           5112, 14540,  4374,  5331,  5139,  8979,  4494,  2016,  5079, 10290,\n",
              "           2323, 14777,  4497,  3320,  3577,  5056,  9199,  9876,    18, 19030,\n",
              "          10999,  9538,  8869,  8531,  2343,  5571,  5067,  8648, 11070,    18,\n",
              "          10337,  8545,  3393,  8697, 11205, 17719,  4492,  5344,    18,  2023,\n",
              "           5124,  2323,  8834,  4494,  2995, 18755,  5093, 13739, 15380,    18,\n",
              "           9657,     3,     2,  2411, 12828,  5091,  5300, 10959,  3742,  5655,\n",
              "           5147,  8882,  5105,  3737,  5213,  5008,  3771, 12029,    16,  9000,\n",
              "           5187,  5083, 15796,  5054,  9337,  5222,  8696,    12, 12828,  9512,\n",
              "          12379,  5221,  5019,    13,  9648, 11302, 10128,  9086,  8455,  9157,\n",
              "          11193,    18,  3742, 10959,  4559, 16431,  9559, 11733, 10027,  8924,\n",
              "           8742,  8590, 12549, 12379,  8808,  8775,  1998,     3,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         dtype=torch.int32),\n",
              "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
              "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
              "  tensor([0., 1.])))"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForNextSentencePrediction.from_pretrained(model_path)\n",
        "model = BERTNextSentenceModel(config, dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39QuRPjV8asV",
        "outputId": "200868d1-ad82-49db-a517-c96f31cbd94a"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at snunlp/KR-Medium were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "\n",
        "logger = TensorBoardLogger(\n",
        "    save_dir=os.path.join(config.log_path, config.task), version=3, name=config.task\n",
        ")\n",
        "\n",
        "acc_checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=data_path+'/sts/checkpoints/'+ config.task, \n",
        "    filename=\"acc_{epoch}_{val_loss:35f}\",\n",
        "    verbose=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_top_k=3,\n",
        "    save_last=True)\n",
        "\n",
        "loss_checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=data_path+'/sts/checkpoints/'+ config.task, \n",
        "    filename=\"val_{epoch}_{val_acc:.3f}\",\n",
        "    verbose=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_last=True)\n",
        "\n",
        "loss_early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.0001,\n",
        "    patience=3,\n",
        "    verbose=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "acc_early_stop_callback = EarlyStopping(\n",
        "    monitor='val_acc',\n",
        "    min_delta=0.0001,\n",
        "    patience=3,\n",
        "    verbose=True,\n",
        "    mode='max'\n",
        ")\n",
        "lrmonitor_callback = LearningRateMonitor(logging_interval='step')"
      ],
      "metadata": {
        "id": "bcmvuRLRRPJk"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    gpus=config.gpus,\n",
        "    callbacks=[acc_checkpoint_callback, loss_checkpoint_callback, lrmonitor_callback],\n",
        "    logger=logger,\n",
        "    max_epochs=2,\n",
        ")\n",
        "\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58230afd4bf0409ca32a6a99a035c399",
            "e25b4601dd34424a92b2a6c570419ccc",
            "d1441270ddb244e4bfc4f665e4196c79",
            "4736de75e01d4adbac83ef73d1802192",
            "eee150f2f4b94e9582e866bdd3ee9885",
            "8313315b92ea470c862053e36cf4a8fc",
            "9eb00af6399a41f49a721e5451d3d481",
            "0255cc3c45ea4bb6a1b2462a0269180e",
            "36d06f5cc64b4006a383007bfe0f539e",
            "3337041c4c3f4df1be495347209e7f39",
            "aff9fb37d3044fe682c77172600e9641"
          ]
        },
        "id": "fO0tsGHDhz1A",
        "outputId": "ac63f08e-5332-4845-a8e4-bc8ed7326d55"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "\n",
            "  | Name    | Type            | Params\n",
            "--------------------------------------------\n",
            "0 | softmax | Softmax         | 0     \n",
            "1 | model   | BertModel       | 101 M \n",
            "2 | cls     | BertOnlyNSPHead | 1.5 K \n",
            "3 | dropout | Dropout         | 0     \n",
            "4 | linear  | Linear          | 1.5 K \n",
            "--------------------------------------------\n",
            "101 M     Trainable params\n",
            "0         Non-trainable params\n",
            "101 M     Total params\n",
            "405.618   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58230afd4bf0409ca32a6a99a035c399"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0126, 0.0256, 0.0067,  ..., 0.0094, 0.0073, 0.0043],\n",
            "         [0.0111, 0.0260, 0.0022,  ..., 0.0103, 0.0103, 0.0031],\n",
            "         [0.0107, 0.0259, 0.0032,  ..., 0.0049, 0.0042, 0.0009],\n",
            "         ...,\n",
            "         [0.0080, 0.0068, 0.0073,  ..., 0.0065, 0.0018, 0.0021],\n",
            "         [0.0084, 0.0081, 0.0085,  ..., 0.0059, 0.0025, 0.0021],\n",
            "         [0.0113, 0.0105, 0.0075,  ..., 0.0133, 0.0069, 0.0046]],\n",
            "\n",
            "        [[0.0078, 0.0050, 0.0034,  ..., 0.0037, 0.0039, 0.0087],\n",
            "         [0.0042, 0.0073, 0.0023,  ..., 0.0061, 0.0097, 0.0058],\n",
            "         [0.0045, 0.0054, 0.0063,  ..., 0.0047, 0.0084, 0.0085],\n",
            "         ...,\n",
            "         [0.0057, 0.0097, 0.0036,  ..., 0.0102, 0.0026, 0.0032],\n",
            "         [0.0067, 0.0071, 0.0034,  ..., 0.0113, 0.0036, 0.0032],\n",
            "         [0.0110, 0.0076, 0.0070,  ..., 0.0064, 0.0075, 0.0083]],\n",
            "\n",
            "        [[0.0083, 0.0063, 0.0053,  ..., 0.0032, 0.0021, 0.0119],\n",
            "         [0.0096, 0.0090, 0.0062,  ..., 0.0052, 0.0047, 0.0121],\n",
            "         [0.0049, 0.0119, 0.0040,  ..., 0.0101, 0.0034, 0.0016],\n",
            "         ...,\n",
            "         [0.0069, 0.0095, 0.0032,  ..., 0.0103, 0.0026, 0.0040],\n",
            "         [0.0076, 0.0072, 0.0030,  ..., 0.0108, 0.0040, 0.0040],\n",
            "         [0.0112, 0.0075, 0.0078,  ..., 0.0065, 0.0045, 0.0111]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.0058, 0.0089, 0.0162,  ..., 0.0160, 0.0179, 0.0020],\n",
            "         [0.0146, 0.0036, 0.0133,  ..., 0.0043, 0.0066, 0.0156],\n",
            "         [0.0093, 0.0017, 0.0119,  ..., 0.0055, 0.0089, 0.0166],\n",
            "         ...,\n",
            "         [0.0096, 0.0059, 0.0191,  ..., 0.0084, 0.0084, 0.0062],\n",
            "         [0.0126, 0.0085, 0.0171,  ..., 0.0070, 0.0097, 0.0083],\n",
            "         [0.0092, 0.0086, 0.0099,  ..., 0.0040, 0.0128, 0.0052]],\n",
            "\n",
            "        [[0.0083, 0.0063, 0.0053,  ..., 0.0032, 0.0021, 0.0119],\n",
            "         [0.0096, 0.0090, 0.0062,  ..., 0.0052, 0.0047, 0.0121],\n",
            "         [0.0049, 0.0119, 0.0040,  ..., 0.0101, 0.0034, 0.0016],\n",
            "         ...,\n",
            "         [0.0069, 0.0095, 0.0032,  ..., 0.0103, 0.0026, 0.0040],\n",
            "         [0.0076, 0.0072, 0.0030,  ..., 0.0108, 0.0040, 0.0040],\n",
            "         [0.0112, 0.0075, 0.0078,  ..., 0.0065, 0.0045, 0.0111]],\n",
            "\n",
            "        [[0.0081, 0.0044, 0.0066,  ..., 0.0070, 0.0039, 0.0062],\n",
            "         [0.0129, 0.0061, 0.0036,  ..., 0.0031, 0.0140, 0.0019],\n",
            "         [0.0052, 0.0021, 0.0087,  ..., 0.0098, 0.0102, 0.0076],\n",
            "         ...,\n",
            "         [0.0083, 0.0070, 0.0056,  ..., 0.0067, 0.0019, 0.0021],\n",
            "         [0.0105, 0.0083, 0.0084,  ..., 0.0064, 0.0028, 0.0023],\n",
            "         [0.0031, 0.0063, 0.0106,  ..., 0.0136, 0.0069, 0.0058]]],\n",
            "       device='cuda:0')\n",
            "outputs tensor([[[0.0126, 0.0256, 0.0067,  ..., 0.0094, 0.0073, 0.0043],\n",
            "         [0.0111, 0.0260, 0.0022,  ..., 0.0103, 0.0103, 0.0031],\n",
            "         [0.0107, 0.0259, 0.0032,  ..., 0.0049, 0.0042, 0.0009],\n",
            "         ...,\n",
            "         [0.0080, 0.0068, 0.0073,  ..., 0.0065, 0.0018, 0.0021],\n",
            "         [0.0084, 0.0081, 0.0085,  ..., 0.0059, 0.0025, 0.0021],\n",
            "         [0.0113, 0.0105, 0.0075,  ..., 0.0133, 0.0069, 0.0046]],\n",
            "\n",
            "        [[0.0078, 0.0050, 0.0034,  ..., 0.0037, 0.0039, 0.0087],\n",
            "         [0.0042, 0.0073, 0.0023,  ..., 0.0061, 0.0097, 0.0058],\n",
            "         [0.0045, 0.0054, 0.0063,  ..., 0.0047, 0.0084, 0.0085],\n",
            "         ...,\n",
            "         [0.0057, 0.0097, 0.0036,  ..., 0.0102, 0.0026, 0.0032],\n",
            "         [0.0067, 0.0071, 0.0034,  ..., 0.0113, 0.0036, 0.0032],\n",
            "         [0.0110, 0.0076, 0.0070,  ..., 0.0064, 0.0075, 0.0083]],\n",
            "\n",
            "        [[0.0083, 0.0063, 0.0053,  ..., 0.0032, 0.0021, 0.0119],\n",
            "         [0.0096, 0.0090, 0.0062,  ..., 0.0052, 0.0047, 0.0121],\n",
            "         [0.0049, 0.0119, 0.0040,  ..., 0.0101, 0.0034, 0.0016],\n",
            "         ...,\n",
            "         [0.0069, 0.0095, 0.0032,  ..., 0.0103, 0.0026, 0.0040],\n",
            "         [0.0076, 0.0072, 0.0030,  ..., 0.0108, 0.0040, 0.0040],\n",
            "         [0.0112, 0.0075, 0.0078,  ..., 0.0065, 0.0045, 0.0111]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.0058, 0.0089, 0.0162,  ..., 0.0160, 0.0179, 0.0020],\n",
            "         [0.0146, 0.0036, 0.0133,  ..., 0.0043, 0.0066, 0.0156],\n",
            "         [0.0093, 0.0017, 0.0119,  ..., 0.0055, 0.0089, 0.0166],\n",
            "         ...,\n",
            "         [0.0096, 0.0059, 0.0191,  ..., 0.0084, 0.0084, 0.0062],\n",
            "         [0.0126, 0.0085, 0.0171,  ..., 0.0070, 0.0097, 0.0083],\n",
            "         [0.0092, 0.0086, 0.0099,  ..., 0.0040, 0.0128, 0.0052]],\n",
            "\n",
            "        [[0.0083, 0.0063, 0.0053,  ..., 0.0032, 0.0021, 0.0119],\n",
            "         [0.0096, 0.0090, 0.0062,  ..., 0.0052, 0.0047, 0.0121],\n",
            "         [0.0049, 0.0119, 0.0040,  ..., 0.0101, 0.0034, 0.0016],\n",
            "         ...,\n",
            "         [0.0069, 0.0095, 0.0032,  ..., 0.0103, 0.0026, 0.0040],\n",
            "         [0.0076, 0.0072, 0.0030,  ..., 0.0108, 0.0040, 0.0040],\n",
            "         [0.0112, 0.0075, 0.0078,  ..., 0.0065, 0.0045, 0.0111]],\n",
            "\n",
            "        [[0.0081, 0.0044, 0.0066,  ..., 0.0070, 0.0039, 0.0062],\n",
            "         [0.0129, 0.0061, 0.0036,  ..., 0.0031, 0.0140, 0.0019],\n",
            "         [0.0052, 0.0021, 0.0087,  ..., 0.0098, 0.0102, 0.0076],\n",
            "         ...,\n",
            "         [0.0083, 0.0070, 0.0056,  ..., 0.0067, 0.0019, 0.0021],\n",
            "         [0.0105, 0.0083, 0.0084,  ..., 0.0064, 0.0028, 0.0023],\n",
            "         [0.0031, 0.0063, 0.0106,  ..., 0.0136, 0.0069, 0.0058]]],\n",
            "       device='cuda:0')\n",
            "outputs[3] tensor([[0.0111, 0.0096, 0.0130,  ..., 0.0031, 0.0038, 0.0038],\n",
            "        [0.0077, 0.0018, 0.0057,  ..., 0.0071, 0.0177, 0.0064],\n",
            "        [0.0092, 0.0151, 0.0170,  ..., 0.0032, 0.0070, 0.0199],\n",
            "        ...,\n",
            "        [0.0087, 0.0107, 0.0045,  ..., 0.0079, 0.0020, 0.0022],\n",
            "        [0.0111, 0.0108, 0.0063,  ..., 0.0081, 0.0027, 0.0027],\n",
            "        [0.0063, 0.0095, 0.0084,  ..., 0.0061, 0.0068, 0.0051]],\n",
            "       device='cuda:0')\n",
            "labels tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-bede52280248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-171-f7d118e5808c>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_label_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_label_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_label_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-171-f7d118e5808c>\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, outputs, labels)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs[3]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert model에 forward return 값 고쳐야함. : linear? relu??\n",
        "# https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bertfornextsentenceprediction"
      ],
      "metadata": {
        "id": "9YnWBdy5iGNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}